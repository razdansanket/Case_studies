{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54351b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some important libraries \n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6535fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84eb62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data =pd.read_csv('product_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e550131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Active classic boxers - There's a reason why o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Active sport boxer briefs - Skinning up Glory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Active sport briefs - These superbreathable no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alpine guide pants - Skin in, climb ice, switc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alpine wind jkt - On high ridges, steep ice an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        description\n",
       "0   1  Active classic boxers - There's a reason why o...\n",
       "1   2  Active sport boxer briefs - Skinning up Glory ...\n",
       "2   3  Active sport briefs - These superbreathable no...\n",
       "3   4  Alpine guide pants - Skin in, climb ice, switc...\n",
       "4   5  Alpine wind jkt - On high ridges, steep ice an..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b252c744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1bd3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           500 non-null    int64 \n",
      " 1   description  500 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "p_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45e55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> list:\n",
    "    \"\"\"\n",
    "    pre process text data by tokenizing, lemmatizing and then removing stop words\n",
    "    Args:\n",
    "        text: product description as a string\n",
    "    Returns:\n",
    "        list of words after pre-processing\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenise words while ignoring punctuation\n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "    \n",
    "    # Lowercase and lemmatise \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13db3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_data = pd.DataFrame(p_data['description'].apply(preprocess_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a900129",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_data['id'] = p_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14a57759",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_data['length'] = pre_processed_data['description'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e3ff221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[active, classic, boxers, reason, boxers, cult...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[active, sport, boxer, brief, skin, glory, req...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[active, sport, brief, superbreathable, fly, b...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[alpine, guide, pant, skin, climb, ice, switch...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[alpine, wind, jkt, high, ridge, steep, ice, a...</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  length\n",
       "0  [active, classic, boxers, reason, boxers, cult...     132\n",
       "1  [active, sport, boxer, brief, skin, glory, req...     146\n",
       "2  [active, sport, brief, superbreathable, fly, b...     125\n",
       "3  [alpine, guide, pant, skin, climb, ice, switch...     184\n",
       "4  [alpine, wind, jkt, high, ridge, steep, ice, a...     239"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b5c6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(window_size: int, train_df: pd.DataFrame, skip_gram: bool = 0, \n",
    "                   vector_size: int = 100, epochs:int = 10, hier_softmax: bool = 1) -> Word2Vec:\n",
    "    \"\"\"\n",
    "    train word2vec model\n",
    "    Args:\n",
    "        window_size: Maximum distance between the current and predicted word within a sentence.\n",
    "        train_data: training data\n",
    "        skip_gram: 1 for skip_gram otherwise CBOW\n",
    "        vector_size: Dimensionality of word vectors\n",
    "        epochs: Number of iterations over the corpus \n",
    "        hier_softmax: If 1, hierarchical softmax will be used for model training. \n",
    "        If 0, and negative is non-zero, negative sampling will be used.\n",
    "    Returns:\n",
    "        gensim word2vec model\n",
    "    \"\"\"\n",
    "    model = Word2Vec(window=window_size, sg=skip_gram, vector_size=vector_size, min_count=3,\n",
    "                     alpha=0.03, min_alpha=0.0007, compute_loss=True, hs=hier_softmax,\n",
    "                     seed=14)\n",
    "    model.build_vocab(train_df, progress_per=200)\n",
    "    model.train(train_df, total_examples=model.corpus_count,\n",
    "                epochs=epochs, report_delay=1, compute_loss=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "460b44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ideal window size as the 90th percentile, so that the model looks for maximum neighbors possible\n",
    "\n",
    "ideal_window_size = int(pre_processed_data['length'].quantile(0.9))\n",
    "w2v_model = train_word2vec(window_size=ideal_window_size, train_df=pre_processed_data['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf3150be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an average embedding for a particular product description by finding vectors for \n",
    "# all words present in that description and then taking an avergae\n",
    "\n",
    "def vectors(df: pd.DataFrame, model: Word2Vec) -> list:\n",
    "    \"\"\"\n",
    "    get an average embedding for a particular product description by finding vectors for \n",
    "    all words present in that description and then taking an average\n",
    "    Args:\n",
    "        df: pre processed input dataframe\n",
    "        model: Word2Vec model\n",
    "    Returns:\n",
    "        list with average word embeddings for each product\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a list for storing the vectors (description into vectors)\n",
    "    global word_embeddings\n",
    "    word_embeddings = []\n",
    "\n",
    "    # Reading the each book description \n",
    "    for sentence in df['description']:\n",
    "        avgword2vec = None\n",
    "        count = 0\n",
    "        for word in sentence:\n",
    "            if word in model.wv.index_to_key:\n",
    "                count += 1\n",
    "                if avgword2vec is None:\n",
    "                    avgword2vec = model.wv[word]\n",
    "                else:\n",
    "                    avgword2vec = avgword2vec + model.wv[word]\n",
    "                \n",
    "        if avgword2vec is not None:\n",
    "            avgword2vec = avgword2vec / count\n",
    "        \n",
    "            word_embeddings.append(avgword2vec)\n",
    "            \n",
    "    return word_embeddings        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4f44142",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = vectors(pre_processed_data, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85fd4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating cosine similarity matrix\n",
    "\n",
    "cos_similarity_matrix=np.dot(np.array(embeddings),np.array(embeddings).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b01de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(input_df: pd.DataFrame, p_id: int, \n",
    "                 similarity_matrix: np.array, top_n: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    calculating top similar products based on cosine similarity matrix\n",
    "    Args:\n",
    "        input_df: raw input dataframe\n",
    "        p_id: product id\n",
    "    Returns:\n",
    "        list with average word embeddings for each product\n",
    "    \"\"\"\n",
    "    print (f'Document: {input_df.loc[p_id, \"description\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Documents:')\n",
    "    similar_ix=np.argsort(similarity_matrix[p_id])[::-1]\n",
    "    similar_ix = similar_ix[:top_n]\n",
    "    for ix in similar_ix:\n",
    "        if ix==p_id:\n",
    "            continue\n",
    "        print('\\n')\n",
    "        print (f'Document: {input_df.loc[ix, \"description\"]}')\n",
    "        print (f'Cosine Similarity : {similarity_matrix[p_id][ix]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "030a979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Active sport boxer briefs - Skinning up Glory requires enough movement without your boxers deciding to poach their own route. The form-fitting Active Sport Boxer Briefs are made from breathable 93% polyester (71% recycled) fabric that's fast-wicking, dries quickly and has 7% spandex for stretch; the seamless waistband and soft leg edges won't roll or bind. The gusseted, flat-sewn 6\" inseam (size M) is offset to prevent inner-thigh chafe. Fly-free with a smooth front panel. Recyclable through the Common Threads Recycling Program.<br><br><b>Details:</b><ul> <li>\"Stretch mesh provides support, open-weave mesh for airflow, wicks efficiently, dries fast\"</li> <li>Seamless construction</li> <li>\"Flat-sewn, gusseted inseam is set forward to prevent inner-thigh chafe\"</li> <li>Fly-free support</li> <li>\"Inseam (size M) is 6\"\"\"</li></ul><br><br><b>Fabric: </b>\"4.6-oz 93% polyester (71% recycled)/7% spandex, with moisture-wicking performance. Recyclable through the Common Threads Recycling Program\"<br><br><b>Weight: </b>(60 g 2.1 oz)<br><br>Made in Israel.\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: Active sport briefs - These superbreathable no-fly briefs are the minimalist's choice for high-octane endeavors. Made from a blend of fast-wicking, quick-drying 93% polyester (71% recycled) and 7% spandex that has both stretch-mesh (for support) and open mesh (for cooling airflow). Soft edging at the leg openings and a seamless waist won't roll or create friction against layers. With a smooth front panel for opacity. Recyclable through the Common Threads Recycling Program.<br><br><b>Details:</b><ul> <li>\"Stretch mesh provides support, open-weave mesh for airflow, wicks efficiently and dries fast\"</li> <li>Seamless construction</li> <li>Leg openings have half-inch self-binding for comfort</li> <li>Fly-free support</li></ul><br><br><b>Fabric: </b>\"4.6-oz 93% polyester (71% recycled)/7% spandex, with moisture-wicking performance. Recyclable through the Common Threads Recycling Program\"<br><br><b>Weight: </b>(49 g 1.7 oz)<br><br>Made in Israel.\n",
      "Cosine Similarity : 17.248619079589844\n",
      "\n",
      "\n",
      "Document: Active briefs - These featherweight, quick-wicking briefs keep you comfortable and dry whether you travel by bus, kayak or stubborn yak. The nonbinding waistband is brushed for next-to-skin softness, and elastic in the leg openings provides a supple fit without constricting. With reversed-out stitching for chafe-free comfort, an easy-access, functional fly and a supportive front panel. Made from 100% polyester (54% recycled) with moisture-wicking performance and Gladiodor natural odor control for the garment. Recyclable through the Common Threads Recycling Program.<br><br><b>Details:</b><ul> <li>Moisture-wicking Capilene 2 fabric with an open-knit weave for breathability</li> <li>Elastic in the leg openings provides a supple fit without constriction; stitching at leg binding is reversed out for chafe-free comfort</li> <li>\"Non-binding, quick-drying waistband is brushed for comfort\"</li></ul><br><br><b>Fabric: </b>4-oz 100% polyester (54% recycled) with Gladiodor natural odor control for the garment. Recyclable through the Common Threads Recycling Program<br><br><b>Weight: </b>(57 g 2 oz)<br><br>Made in USA.\n",
      "Cosine Similarity : 16.43300437927246\n",
      "\n",
      "\n",
      "Document: Active briefs - Whether you're beating the heat in Bali or skinning up your favorite cirque, these ultrasoft, lightweight briefs provide exceptional stretch and moisture-management for keeping you comfortable and dry. They also glide easily beneath layers. A seamless waistband lies flat and won't roll or bind; newly redesigned single-sided leg binding stays put and is low-profile. With a breathable mini-rib crotch. Solids and prints: 4.6-oz 96% nylon/4% spandex. Stripes: 5.6-oz 93% polyester (58% recycled)/7% spandex.<br><br><b>Details:</b><ul> <li>\"Ultrasoft, lightweight fabric with stretch and moisture management\"</li> <li>\"Seamless waistband lies flat, won't roll or bind, breathable mini-rib crotch, soft, single-sided binding at leg openings wont chafe or creep\"</li></ul><br><br><b>Fabric: </b>Solids and prints: 4.6-oz 96% nylon/4% spandex. Stripes: 5.6-oz 94% polyester (58% recycled)/7% spandex. All with moisture-wicking performance<br><br><b>Weight: </b>(28 g 1 oz)<br><br>Made in Israel.\n",
      "Cosine Similarity : 16.09368896484375\n",
      "\n",
      "\n",
      "Document: Barely bikini - Better than going commando, our petal-soft Barely Bikini wicks moisture and breathes to keep you comfortable with a feminine lace-like texture and seamless construction for ultimate comfort. Low-rise with the least coverage of our bottoms, this bikini style minimizes panty lines and single-ply elastic binding is featherweight and won't chafe. Made from a blend of 94% polyester (73% recycled)/6% spandex. Pairs with our Barely Bra and Barely Everyday Bra. Recyclable through the Common Threads Recycling Program.<br><br><b>Details:</b><ul> <li>Petal-soft and featherweight recycled-polyester/spandex blend manages moisture and breathes to keep you cool</li> <li>Seamless construction</li> <li>Lace-like texture is integral to fabric</li> <li>Pairs with our Women's Barely Bra and Women's Barely Everyday Bra</li></ul><br><br><b>Fabric: </b>\"4.6-oz 94% polyester (73% recycled)/6% spandex, with a moisture-wicking finish. Recyclable through the Common Threads Recycling Program\"<br><br><b>Weight: </b>(17 g 0.6 oz)<br><br>Made in Israel.\n",
      "Cosine Similarity : 15.656575202941895\n"
     ]
    }
   ],
   "source": [
    "most_similar(p_data, 1, cos_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e3f5c",
   "metadata": {},
   "source": [
    "#### Products which have higher cosine similarity score are similar to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e7aa6",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* G. Linden, B. Smith and J. York, \"Amazon.com recommendations: item-to-item collaborative filtering,\" in IEEE Internet Computing, vol. 7, no. 1, pp. 76-80, Jan.-Feb. 2003, doi: 10.1109/MIC.2003.1167344.\n",
    "* Goldberg, Yoav, and Omer Levy. \"word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method.\" arXiv preprint arXiv:1402.3722 (2014).\n",
    "* https://towardsdatascience.com/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96     \n",
    "* https://www.analyticsvidhya.com/blog/2019/07/how-to-build-recommendation-system-word2vec-python/\n",
    "* https://radimrehurek.com/gensim/models/word2vec.html\n",
    "* https://www.kdnuggets.com/2020/08/content-based-recommendation-system-word-embeddings.html\n",
    "* https://towardsdatascience.com/calculating-document-similarities-using-bert-and-other-models-b2c1a29c9630"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
